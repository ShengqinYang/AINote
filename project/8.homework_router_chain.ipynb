{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Homework\n",
    "\n",
    "#### 扩展 Demo：实现生物、计算机和汉语言文学老师 PromptTemplates 及对应 Chains"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "import configparser, os\n",
    "from langchain.chains import (RouterChain, SequentialChain, LLMChain, MultiRouteChain, ConversationChain)\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "conf = configparser.ConfigParser()\n",
    "conf.read('../config.ini')\n",
    "api_key = conf.get(\"Openai\", \"api_key\")  # 在config.ini中配置自己的APIkey\n",
    "os.environ[\"HTTP_PROXY\"] = conf.get(\"Proxy\", \"HTTP_PROXY\")  # 配置自己的代理\n",
    "os.environ[\"HTTPS_PROXY\"] = conf.get(\"Proxy\", \"HTTPS_PROXY\")\n",
    "chat_model = \"gpt-3.5-turbo\"\n",
    "text_model = \"text-davinci-003\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:04:58.469018Z",
     "start_time": "2023-08-11T09:04:58.464855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "physics_template = \"\"\"你是一位非常聪明的物理教授。\n",
    "你擅长以简洁易懂的方式回答关于物理的问题。\n",
    "当你不知道某个问题的答案时，你会坦诚承认。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "math_template = \"\"\"你是一位很棒的数学家。你擅长回答数学问题。\n",
    "之所以如此出色，是因为你能够将难题分解成各个组成部分，\n",
    "先回答这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"你是一位很优秀的生物学家。\n",
    "你很擅长用简单易懂方式回答关于生物学的知识，先简单叙述问题的概念，在举一个生活的例子说明。\n",
    "这个问题是：{input}\n",
    "\"\"\"\n",
    "\n",
    "chinese_language_template = \"\"\"你是一位擅长汉语语言文学的教授，擅长做答汉语语言方面的问题。\n",
    "答题时候直接切中要害，直奔给分点，多给作品例子来回答，会增强说服力。\n",
    "这个问题是：{input}\n",
    "\"\"\"\n",
    "\n",
    "computer_template = \"\"\"你是一位计算机软件和硬件方面的专家，软件方面：擅长各种编程语言以及编程技巧，硬件方面：擅长各种硬件设施以及配置调优等。\n",
    "解答下面的问题，解答时候，软件方面：1.写出代码 2.加上简单的注释，硬件方面简单的步骤说明。\n",
    "这个问题是：{input}\"\"\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:04:59.242474Z",
     "start_time": "2023-08-11T09:04:59.239232Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"物理\",\n",
    "        \"description\": \"适用于回答物理问题\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"数学\",\n",
    "        \"description\": \"适用于回答数学问题\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"生物\",\n",
    "        \"description\": \"适用于回答生物学问题\",\n",
    "        \"prompt_template\": biology_template,\n",
    "    }, {\n",
    "        \"name\": \"计算机\",\n",
    "        \"description\": \"适用于回答计算机软件和硬件方面的问题\",\n",
    "        \"prompt_template\": computer_template,\n",
    "    }, {\n",
    "        \"name\": \"语文\",\n",
    "        \"description\": \"适用于回答汉语语言文学方面的问题\",\n",
    "        \"prompt_template\": chinese_language_template,\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:04:59.842321Z",
     "start_time": "2023-08-11T09:04:59.838060Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# 创建一个空的目标链字典，用于存放根据prompt_infos生成的LLMChain。\n",
    "destination_chains = {}\n",
    "llm = OpenAI(openai_api_key=api_key)\n",
    "for prompt in prompt_infos:\n",
    "    name = prompt['name']\n",
    "    description = prompt['description']\n",
    "    prompt_template = prompt['prompt_template']\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "# print(destination_chains.keys())\n",
    "\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:05:00.494595Z",
     "start_time": "2023-08-11T09:05:00.491579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "langchain.chains.conversation.base.ConversationChain"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:05:01.589068Z",
     "start_time": "2023-08-11T09:05:01.584739Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 这段代码定义了一个chain对象（LLMRouterChain），该对象首先使用router_chain来决定哪个destination_chain应该被执行，如果没有合适的目标链，则默认使用default_chain。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物学问题\n",
      "计算机: 适用于回答计算机软件和硬件方面的问题\n",
      "语文: 适用于回答汉语语言文学方面的问题\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "print(router_template)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "# 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:27:50.485846Z",
     "start_time": "2023-08-11T09:27:50.484040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from langchain.chains import MultiPromptChain\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    default_chain= default_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    verbose=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:31:09.948241Z",
     "start_time": "2023-08-11T09:31:09.944304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangshengqin/my_pyenv/AINote/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语文: {'input': '谁写了“床前明月光，疑是地上霜”？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n这是李白的诗句，出自《静夜思》。《静夜思》是李白的代表作之一，诗中表达了他对家乡的思念，对爱的痴迷，也抒发了他对静夜的情感。这首诗也把秦淮河畔的景色描绘得淋漓尽致，如：“沉醉不知归路，入眠不知东西。”这首诗被称为“李白的绝句宝库”，其中'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"“床前明月光，意思地上霜”是谁写的？\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:31:19.647927Z",
     "start_time": "2023-08-11T09:31:11.594326Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "计算机: {'input': '用Python编写归并排序算法'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n\\n步骤一：定义一个归并排序函数，函数接受一个列表作为参数。\\n\\n步骤二：如果列表的长度小于或等于1，那么直接返回这个列表，因为它已经排序完成。\\n\\n步骤三：取列表中间的元素，将列表一分为二。\\n\\n步骤四：调用归并排序函数，对这两个分开的列表分别进行排序。\\n\\n步'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"用python写一个归并排序\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:34:42.957188Z",
     "start_time": "2023-08-11T09:34:28.568386Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
