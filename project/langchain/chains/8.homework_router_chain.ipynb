{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Homework\n",
    "\n",
    "#### 扩展 Demo：实现生物、计算机和汉语言文学老师 PromptTemplates 及对应 Chains"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import configparser, os\n",
    "from langchain.chains import (RouterChain, SequentialChain, LLMChain, MultiRouteChain, ConversationChain)\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "conf = configparser.ConfigParser()\n",
    "current_directory = os.path.dirname(os.path.realpath('__file__'))\n",
    "config_file_path = os.path.join(current_directory, '..', '..', '..', 'config.ini')\n",
    "conf.read(config_file_path)\n",
    "api_key = conf.get(\"Openai\", \"api_key\")  # 在config.ini中配置自己的APIkey\n",
    "os.environ[\"HTTP_PROXY\"] = conf.get(\"Proxy\", \"HTTP_PROXY\")  # 配置自己的代理\n",
    "os.environ[\"HTTPS_PROXY\"] = conf.get(\"Proxy\", \"HTTPS_PROXY\")\n",
    "chat_model = \"gpt-3.5-turbo\"\n",
    "text_model = \"text-davinci-003\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T03:13:39.457413Z",
     "start_time": "2023-09-27T03:13:38.108368Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "physics_template = \"\"\"你是一位非常聪明的物理教授。\n",
    "你擅长以简洁易懂的方式回答关于物理的问题。\n",
    "当你不知道某个问题的答案时，你会坦诚承认。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "math_template = \"\"\"你是一位很棒的数学家。你擅长回答数学问题。\n",
    "之所以如此出色，是因为你能够将难题分解成各个组成部分，\n",
    "先回答这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"你是一位很优秀的生物学家。\n",
    "你很擅长用简单易懂方式回答关于生物学的知识，先简单叙述问题的概念，在举一个生活的例子说明。\n",
    "这个问题是：{input}\n",
    "\"\"\"\n",
    "\n",
    "chinese_language_template = \"\"\"你是一位擅长汉语语言文学的教授，擅长做答汉语语言方面的问题。\n",
    "答题时候直接切中要害，直奔给分点，多给作品例子来回答，会增强说服力。\n",
    "这个问题是：{input}\n",
    "\"\"\"\n",
    "\n",
    "computer_template = \"\"\"你是一位计算机软件和硬件方面的专家，软件方面：擅长各种编程语言以及编程技巧，硬件方面：擅长各种硬件设施以及配置调优等。\n",
    "解答下面的问题，解答时候，软件方面：1.写出代码 2.加上简单的注释，硬件方面简单的步骤说明。\n",
    "这个问题是：{input}\"\"\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T03:13:45.364312Z",
     "start_time": "2023-09-27T03:13:45.362070Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"物理\",\n",
    "        \"description\": \"适用于回答物理问题\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"数学\",\n",
    "        \"description\": \"适用于回答数学问题\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"生物\",\n",
    "        \"description\": \"适用于回答生物学问题\",\n",
    "        \"prompt_template\": biology_template,\n",
    "    }, {\n",
    "        \"name\": \"计算机\",\n",
    "        \"description\": \"适用于回答计算机软件和硬件方面的问题\",\n",
    "        \"prompt_template\": computer_template,\n",
    "    }, {\n",
    "        \"name\": \"语文\",\n",
    "        \"description\": \"适用于回答汉语语言文学方面的问题\",\n",
    "        \"prompt_template\": chinese_language_template,\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T07:31:18.951322Z",
     "start_time": "2023-08-15T07:31:18.948931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 创建一个空的目标链字典，用于存放根据prompt_infos生成的LLMChain。\n",
    "destination_chains = {}\n",
    "llm = OpenAI(openai_api_key=api_key)\n",
    "for prompt in prompt_infos:\n",
    "    name = prompt['name']\n",
    "    description = prompt['description']\n",
    "    prompt_template = prompt['prompt_template']\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "# print(destination_chains.keys())\n",
    "\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T07:31:20.217539Z",
     "start_time": "2023-08-15T07:31:20.207710Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "langchain.chains.conversation.base.ConversationChain"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T08:45:26.755291Z",
     "start_time": "2023-08-13T08:45:26.724135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 这段代码定义了一个chain对象（LLMRouterChain），该对象首先使用router_chain来决定哪个destination_chain应该被执行，如果没有合适的目标链，则默认使用default_chain。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物学问题\n",
      "计算机: 适用于回答计算机软件和硬件方面的问题\n",
      "语文: 适用于回答汉语语言文学方面的问题\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "print(router_template)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "# 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T07:31:20.222520Z",
     "start_time": "2023-08-15T07:31:20.218451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from langchain.chains import MultiPromptChain\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    default_chain=default_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    verbose=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T08:46:05.987803Z",
     "start_time": "2023-08-13T08:46:05.982787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangshengqin/my_pyenv/AINote/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语文: {'input': '谁写了“床前明月光，疑是地上霜”？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n答：这是唐代诗人李白所写的诗句，全诗名为《望庐山瀑布》，整首诗充满了大自然的恢弘壮阔，赞美大自然的美景。'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"“床前明月光，意思地上霜”是谁写的？\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T08:46:19.826700Z",
     "start_time": "2023-08-13T08:46:13.228303Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "计算机: {'input': '如何用python写一个归并排序'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-x42xnbIQNTmMDq6adIeja9TZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'算法？\\n\\n软件方面：\\n# 定义归并排序的函数\\ndef mergeSort(arr): \\n \\n    # 如果传入的数组长度小于2，说明这个数组中只有一个元素，\\n    # 或者这个数组为空，不需要排序，直接返回\\n    if len(arr) < 2: \\n        return arr \\n  \\n    # 计算数组中间位置\\n    mid = len(arr)//2 \\n  \\n    # 使用list分片，将数组分成两部分\\n    left, right = arr[:mid], arr'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"用python写一个归并排序\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T08:46:42.046074Z",
     "start_time": "2023-08-13T08:46:30.967659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "计算机: {'input': '解释下linux环境下top命令用法'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n\\n软件方面：\\ntop命令用来实时查看系统的CPU、内存使用情况，它是一个实时刷新的动态显示进程的工具。\\n\\n硬件方面：\\n1.在Linux环境下，打开终端，输入“top”命令\\n2.等待几秒钟，就能看到实时显示的的系统CPU、内存使用情况'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"解释下linux环境下top命令用法\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T08:48:20.055580Z",
     "start_time": "2023-08-13T08:48:14.278579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
