## 第一章：大模型基础--理论与技术的演进（第二节课）
### 第一部分：课后习题
<hr />

### 第二部分：相关名词解释
<hr />

### 第三部分：一些问答
##### 1、SFT fine-tuning instruction turing 什么区别
```text
SFT(Supervised Fine-Tuning): 这是一个监督学习过程，即通过人工标注的训练数据集来调整模型的参数。在这个过程中，模型学习将输入映射到预期的输出。这通常是在预训练阶段后进行的，以便将模型适应于特定任务。
2.Fine-tuning: 这是一种通用的深度学习训练策略，通常在预训练模型基础上进行，以适应新任务。通过对预训练模型的参数进行微调，使模型能够在特定任务上表现更好。SFT就是一种Fine-tuning的策路Instruction tuning: 这是一种新型的微调技术，主要用于增强模型对特定指令的响应。在这个过程中，模型被训练来理解和执行指令，比如生成特定类型的文本。这种方法的关键在于设计有效的指令，使模型能够正确理解并生成预期的输出。
因此，SFT和Fine-tuning是一种类似的策略，目的是微调模型的参数以适应特定任务。而Instruction tuning则是一种更加特定的微调策略，专注于提高模型对指令的响应,

fine-tuning是一种在特定标注数据集上进行模型权重微调的方法。在不同的下游任务和基准测试上，各种tuning表现也不尽相同。原则上，不存在谁更先进
```
<br />

##### 2、我要用大模型做分类，我用openai的finetune，效果很好，6w条语料4轮epoch可以到0.94accuracy。但是高质量的语料标注是个难活。我朋友告诉我，prompt-tuning用的语料更少，而语料治疗要求没那么高，而效果更好。
```text
文本分类是一个经典下游任务，如果你的预料本身并没有给使用的OpenAI基础模型增加额外的知识，那么prompt-tuning确实是更有性价比的
关于prompt-based learning目的是让大家理解如何从 standard prompt 演进到适用性极高的 ToT 的。
```
<br />

##### 3、思维链，是指提示词提问时的思维链，还是模型回答问题时运用思维链来回答？我的理解是后者，因为昨天的后半程课，全程讲的是模型在回答问题时的思维链逻辑推理，但是助教直播间说的是提示词提问时用思维链方式。能捋一捋吗？昨天并没有讲什么样的提示词规则更高效

```text
对于一个模型在回答问题时的思维链逻辑推理，可以将其理解为模型对输入问题进行处理和分析的过程。这个过程可以看作是一种思维链，其中模型通过触发不同的关联或推理机制来生成答案。
当使用提示词提问时，思维链方式可以指引你以一种递进的思考方式来构建问题。你可以从一个提示词出发，将其作为起点，然后依次深入探索相关的概念、关联或细节，构建一个连贯的问题链条。每个问题都基于前一个问题的答案或信息，从而逐步扩展和深化对问题的理解。
通过思维链方式提问可以帮助你更系统地探索和获取信息，从而得到更准确、全面的回答。这种方法可以用于讨论复杂的主题、解决问题或促进深入思考和探索。
```
<br />

##### 4、请教一个小小问题 我看观看视频时 发现如图中的关于Encoder-decoder Architecture的公式和图示 虽然是引自原论文 但我认为高亮部分的公式和Sample是有差异的：
1. 公式中：hi是encoder的hidden state, cj是context vector为了计算出decoder的hidden state（有点类似hi是输入cj是输出）, 所以attention weights即aij的角标关系是先i后j, 即先hi输入后cj输出
2. 但Sample公式中：c2 = a21·h1 + a22·h2 + a23·h3 其attention weights即aij的角标关系是先j后i, 其实与公式正好相反, 我觉得这个Sample的算式表达是有问题的
![avatar](resource/笔记2-3-4.1.png)

```text
要理解这个问题呢，有几个关键第一个就是这个角标你提的很好，l和J在这个表格里面呢，其实我们能看到1呢，其实是指输入我们的encounter编码器的隐藏状态。Hi这个1表示的是输入的一个特定位置，J是输出，就是我们的这个 dcoder，我们的解码器想要去定位的那个位置，就那个特定的词，所以I通常指的是我们图当中的们的比如说 S2Y2 这样的一个输出这个是没问题的，然后在表格里面呢，其实我们能看到它的逻辑是顺畅的，就是我们用 CJ。就是表达我们输出的地接一个隐藏层的状态它是由这个矩阵乘上每一个输入乘出来的的和。
至于在那个图例里面，为什么感觉好像它的角标倒过来了啊，我的理解啊，个人的理解，作者这里呢更多的是想通过这个图例来表达含义。但是在这里呢，其实就。某种层面上把这个阿尔法这个矩阵，他做了一个转制啊，做这个转制也是为了这个图做的更好看，因为你看这个图中呢，其实中间那一部分是一个神经网络，然后这个神经网络的输出呢，是一个S。然后呢，它的这个每一每一行是一个 S，每一列呢，上面又变成了一个H，这个顺序呢，就跟我们其实正常认为的应该输入是H，输出是 S，有点倒过来了，所以它是为了这个图例的表达方便。我理解在图例当中，把这个阿尔法矩阵做了一个转制，对就相当于它的行和列做了一次交换
但就理解公式而言，你从表格来看是没有问题的，就表格可能会更明确一点，不管是S还是 C，其实都表达的是解码层的一个特定位置的隐藏成状态，或者它对应的上下文向量，那么对应的这个位置这个J就比如说我们这里看到的 S2 或者C2，都是说锚定了一个输出的位置，然后把这个。腾讯 which，就是我们的注意力权重和对应的输入的这个hi去做相乘，然后再做这个西格玛，就是把它求和，这个逻辑是没问题的。核心就是这里我理解是为了图的表达形式上更直观，做了一次转制的一个展示啊，这我个人的理解。
```
```text 
好的 明白了 非常感谢彭老师的细致解答 我一开始也是感觉把矩阵转置了 但没明白为什么要转置 你说NN剪头对应输出所以横向是输出S 这么说的话确实有道理 我还特意重画了一下 ￼
```
![avatar](resource/笔记2-3-4.2.png)